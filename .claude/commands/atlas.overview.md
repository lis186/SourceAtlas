---
description: Get project overview - scan <5% of files to achieve 70-80% understanding
model: haiku
allowed-tools: Bash, Glob, Grep, Read, Write
argument-hint: [path] [--save] (e.g., "src/api" or ". --save")
---

# SourceAtlas: Project Overview (Stage 0 Fingerprint)

> **Constitution**: This command operates under [ANALYSIS_CONSTITUTION.md](../../ANALYSIS_CONSTITUTION.md) v1.0
>
> Key principles enforced:
> - Article I: é«˜ç†µå„ªå…ˆã€æƒææ¯”ä¾‹ä¸Šé™
> - Article II: å¼·åˆ¶æ’é™¤ç›®éŒ„
> - Article III: å‡è¨­æ•¸é‡é™åˆ¶ã€å¿…è¦å…ƒç´ 
> - Article IV: è­‰æ“šæ ¼å¼è¦æ±‚

## Context

**Arguments**: ${ARGUMENTS:-.}

**Save Mode**: Check if `--save` is in arguments. If present:
- Remove `--save` from path argument
- After analysis, save YAML to `.sourceatlas/overview.yaml`
- Create `.sourceatlas/` directory if needed

**Analysis Target**: Parse from arguments (default: current directory)

**Goal**: Generate a comprehensive project fingerprint by scanning <5% of files to achieve 70-80% understanding in 10-15 minutes.

---

## Your Task

Execute **Stage 0 Analysis Only** - generate a project overview using information theory principles.

### Phase 1: Project Detection & Scale-Aware Planning (2-3 minutes)

**IMPORTANT**: Use the enhanced detection script for accurate file counts and scale-aware recommendations.

```bash
# Run enhanced detection script (RECOMMENDED)
# Will try global install first, then local
bash ~/.claude/scripts/atlas/detect-project-enhanced.sh ${ARGUMENTS:-.} 2>/dev/null || \
bash scripts/atlas/detect-project-enhanced.sh ${ARGUMENTS:-.}
```

The script will:
- Detect project type and language
- Count actual code files (excluding .venv, node_modules, vendor, etc.)
- Determine project scale (TINY/SMALL/MEDIUM/LARGE/VERY_LARGE)
- Recommend file scan limits (to stay <10%)
- Suggest hypothesis targets (scale-aware)
- **Detect context** (Git branch, monorepo subdirectory, package name)

**Scale-Aware Scan Limits**:
- **TINY** (<5 files): Scan 1-2 files max (50% max to avoid over-scanning tiny projects)
- **SMALL** (5-15 files): Scan 2-3 files (10-20%)
- **MEDIUM** (15-50 files): Scan 4-6 files (8-12%)
- **LARGE** (50-150 files): Scan 6-10 files (4-7%)
- **VERY_LARGE** (>150 files): Scan 10-15 files (3-7%)

**Scale-Aware Hypothesis Targets**:
- **TINY**: 5-8 hypotheses (simple projects have fewer dimensions)
- **SMALL**: 7-10 hypotheses
- **MEDIUM**: 10-15 hypotheses
- **LARGE**: 12-18 hypotheses
- **VERY_LARGE**: 15-20 hypotheses

### Phase 2: High-Entropy File Prioritization (5-8 minutes)

Apply information theory - **high-entropy files contain disproportionate information**.

**Scan Priority Order**:

1. **Documentation** (Highest entropy)
   - README.md, CLAUDE.md, CONTRIBUTING.md
   - docs/, documentation/

2. **Configuration Files** (Project-level decisions)
   - package.json, composer.json, Gemfile, etc.
   - Config files in root
   - docker-compose.yml, Dockerfile

3. **Core Models** (Data structure - scan 3-5 only)
   - models/, entities/, domain/
   - Pick the most important ones

4. **Entry Points** (Architecture patterns - scan 1-2 examples)
   - Controllers, Routes, API definitions
   - main.*, index.*, app.*

5. **Tests** (Development practices - scan 1-2 examples)
   - Key test files to understand testing approach

**Execute scans**:

```bash
# Use helper script if available (try global first, then local)
bash ~/.claude/scripts/atlas/scan-entropy.sh ${ARGUMENTS:-.} 2>/dev/null || \
bash scripts/atlas/scan-entropy.sh ${ARGUMENTS:-.} 2>/dev/null
```

### Phase 3: Generate Hypotheses (3-5 minutes)

Based on scanned files, generate **scale-appropriate hypotheses** (use targets from Phase 1) about:

**Technology Stack**:
- Primary language(s) and versions
- Framework(s) and major dependencies
- Database(s) and storage solutions
- Testing frameworks

**Architecture**:
- Overall pattern (MVC, Clean Architecture, Microservices, etc.)
- Directory structure conventions
- Layering and separation of concerns
- Design patterns used

**Development Practices**:
- Code quality indicators
- Testing coverage and approach
- Documentation depth
- Git workflow patterns

**AI Collaboration** (SourceAtlas Signature Analysis):
- Level 0-4 detection:
  - Level 0: Traditional development (5-8% comments, inconsistent style)
  - Level 3: Systematic AI collaboration (CLAUDE.md present, 15-20% comments, 98%+ consistency)
- Look for: CLAUDE.md, .cursor/rules/, high comment density, conventional commits

**Business Domain**:
- What does this project do?
- Key entities and concepts
- Main features

Each hypothesis must include:
- **Confidence level** (0.0-1.0)
- **Evidence** (specific files/lines)
- **Validation method** (how to verify in Stage 1)

---

## Output Format

Generate output in **YAML format** (standard, ecosystem-supported):

```yaml
metadata:
  project_name: "[detected name]"
  scan_time: "[ISO 8601 timestamp]"
  target_path: "${ARGUMENTS:-.}"
  total_files: [actual count after exclusions]
  scanned_files: [files read]
  scan_ratio: "[percentage]"
  project_scale: "[TINY|SMALL|MEDIUM|LARGE|VERY_LARGE]"
  constitution_version: "1.1"
  # Branch-Aware Context (v2.8.2)
  context:
    git_branch: "[branch name or null]"
    relative_path: "[path within repo or null]"
    package_name: "[detected package name or null]"

project_fingerprint:
  project_type: "[WEB_APP|CLI|LIBRARY|MOBILE_APP|MICROSERVICE|MONOREPO]"
  scale: "[TINY|SMALL|MEDIUM|LARGE|VERY_LARGE]"
  # TINY: <500 LOC, SMALL: 500-2k, MEDIUM: 2k-10k, LARGE: 10k-50k, VERY_LARGE: >50k
  primary_language: "[language + version]"
  framework: "[framework + version]"
  architecture: "[pattern name]"

tech_stack:
  backend:
    language: "[name + version]"
    framework: "[name + version]"
    database: "[name + version]"

  frontend:  # if applicable
    language: "[name]"
    framework: "[name]"

  infrastructure:  # if applicable
    containerization: "[Docker/none]"
    orchestration: "[K8s/none]"

hypotheses:
  architecture:
    - hypothesis: "[architectural pattern description]"
      confidence: 0.0-1.0
      evidence: "[file:line references]"
      validation_method: "[how to verify]"

  tech_stack:
    - hypothesis: "[technology decision]"
      confidence: 0.0-1.0
      evidence: "[file:line references]"
      validation_method: "[how to verify]"

  development:
    - hypothesis: "[development practice]"
      confidence: 0.0-1.0
      evidence: "[file:line references]"
      validation_method: "[how to verify]"

  ai_collaboration:
    level: 0-4
    confidence: 0.0-1.0
    evidence: "[specific indicators]"
    indicators:
      - "[indicator 1]"
      - "[indicator 2]"

  business:
    - hypothesis: "[business domain insight]"
      confidence: 0.0-1.0
      evidence: "[file:line references]"
      validation_method: "[how to verify]"

scanned_files:
  - file: "[path/to/file]"
    reason: "[why scanned]"
    key_insight: "[main learning]"

summary:
  understanding_depth: "[70-80%]"
  key_findings:
    - "[finding 1]"
    - "[finding 2]"
    - "[finding 3]"

## Recommended Next

<!-- æ ¹æ“šåˆ†æç™¼ç¾å‹•æ…‹å»ºè­°ï¼Œçœç•¥æ­¤å€å¡Šè‹¥æ»¿è¶³çµæŸæ¢ä»¶ -->

| # | å‘½ä»¤ | ç”¨é€” |
|---|------|------|
| 1 | `/atlas.pattern "[patternåç¨±]"` | [åŸºæ–¼ç™¼ç¾çš„ç†ç”±] |
| 2 | `/atlas.flow "[å…¥å£é»]"` | [åŸºæ–¼ç™¼ç¾çš„ç†ç”±] |

ğŸ’¡ è¼¸å…¥æ•¸å­—ï¼ˆå¦‚ `1`ï¼‰æˆ–è¤‡è£½å‘½ä»¤åŸ·è¡Œ
```

---

## Critical Rules

1. **Scale-Aware Scanning**: Follow recommended file limits from Phase 1 detection
2. **Exclude Common Bloat**: Never scan .venv/, node_modules/, vendor/, __pycache__, .git/
3. **Time Limit**: Complete in 10-15 minutes (though usually takes 0-5 minutes)
4. **Hypothesis Quality**: Each must have confidence level and evidence
5. **Scale-Aware Targets**: Use hypothesis targets appropriate for project scale
6. **No Deep Diving**: Understand structure > implementation details
7. **STOP after Stage 0**: Do not proceed to validation or git analysis

---

## Tips for Efficient Analysis

- **README first**: Often contains 30-40% of project understanding
- **Config files are gold**: Technology decisions in one place
- **Sample, don't enumerate**: Read 2-3 models, not all 50
- **Pattern over detail**: Identify the pattern from 1-2 examples
- **Trust your hypotheses**: 70-80% confidence is the goal, not 100%

---

## Handoffs åˆ¤æ–·è¦å‰‡

> éµå¾ª **Constitution Article VII: Handoffs åŸå‰‡**

### çµæŸæ¢ä»¶ï¼ˆçœç•¥ `recommended_next`ï¼‰

æ ¹æ“š Section 7.2ï¼Œæ»¿è¶³ä»¥ä¸‹ä»»ä¸€æ¢ä»¶æ™‚çœç•¥ï¼š
- **å°ˆæ¡ˆå¤ªå°**ï¼šTINYï¼ˆ<10 filesï¼‰å¯ç›´æ¥é–±è®€
- **ç™¼ç¾å¤ªæ¨¡ç³Š**ï¼šç„¡æ³•çµ¦å‡ºé«˜ä¿¡å¿ƒï¼ˆ>0.7ï¼‰çš„å…·é«”åƒæ•¸
- **ç›®æ¨™å·²é”æˆ**ï¼šAI å”ä½œ Level â‰¥3 ä¸”è¦æ¨¡ TINY/SMALLï¼ˆå¯ç›´æ¥é–‹ç™¼ï¼‰

çœç•¥æ™‚æä¾›çµæŸæç¤ºï¼š
```markdown
âœ… **åˆ†æå·²è¶³å¤ ** - å°ˆæ¡ˆè¦æ¨¡å°ï¼Œå¯ç›´æ¥é–±è®€å…¨éƒ¨æª”æ¡ˆé–‹å§‹é–‹ç™¼
```

### å»ºè­°é¸æ“‡ï¼ˆæ ¹æ“šç™¼ç¾ï¼‰

| ç™¼ç¾ | å»ºè­°å‘½ä»¤ | åƒæ•¸ä¾†æº |
|------|---------|---------|
| æ˜ç¢ºè¨­è¨ˆ patterns | `/atlas.pattern` | ç™¼ç¾çš„ pattern åç¨± |
| æ¶æ§‹è¤‡é›œï¼ˆå¤šå±¤/å¾®æœå‹™ï¼‰ | `/atlas.flow` | ä¸»è¦å…¥å£é»æª”æ¡ˆ |
| è¦æ¨¡ â‰¥ LARGE | `/atlas.history` | ç„¡éœ€åƒæ•¸ |
| é«˜é¢¨éšªå€åŸŸ | `/atlas.impact` | é¢¨éšªæª”æ¡ˆ/æ¨¡çµ„å |

### è¼¸å‡ºæ ¼å¼ï¼ˆSection 7.3ï¼‰

ä½¿ç”¨ç·¨è™Ÿè¡¨æ ¼ï¼š
```markdown
| # | å‘½ä»¤ | ç”¨é€” |
|---|------|------|
| 1 | `/atlas.pattern "repository"` | ç™¼ç¾ Repository æ¨¡å¼è¢« 15 è™•ä½¿ç”¨ |
```

### å“è³ªè¦æ±‚ï¼ˆSection 7.4-7.5ï¼‰

- **åƒæ•¸å…·é«”**ï¼šå¦‚ `"repository"` é `"ç›¸é—œ pattern"`
- **æ•¸é‡é™åˆ¶**ï¼š1-2 å€‹å»ºè­°ï¼Œä¸å¼·åˆ¶å¡«æ»¿
- **ç”¨é€”æ¬„ä½**ï¼šå¼•ç”¨å…·é«”ç™¼ç¾ï¼ˆæ•¸å­—ã€æª”æ¡ˆåï¼‰

---

## Save Mode (--save)

If `--save` flag is present in arguments:

1. **Create directory** (if needed):
```bash
mkdir -p .sourceatlas
```

2. **Save YAML output** to `.sourceatlas/overview.yaml`

3. **Confirm save**:
```
ğŸ’¾ å·²å„²å­˜è‡³ .sourceatlas/overview.yaml
```

**File naming for subdirectory analysis**:
- Root analysis: `.sourceatlas/overview.yaml`
- Subdirectory (e.g., `src/api`): `.sourceatlas/overview-src-api.yaml`
